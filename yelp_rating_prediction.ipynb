{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yelp Restaurant Rating Prediction\n",
    "\n",
    "## Project Description\n",
    "The project goal is to predict restaurant overall ratings on yelp\n",
    "in New York City, using multiple features of restaurants that we will\n",
    "extract using the yelp API. Our motivation is to help determine how\n",
    "successful a new restaurant business might be, given certain known\n",
    "characteristics of it.\n",
    "\n",
    "We will use the Yelp API, with the help of pandas, to acquire raw data\n",
    "from restaurants. Then we will extract reasonable features such as\n",
    "location, open hours, whether it takes reservations, whether it has\n",
    "delivery service, whether there is parking space, and whether it\n",
    "provides free wifi etc., from the parsed data, and combine with the\n",
    "overall ratings, which is a numerical value ranging from 0 to 5, as\n",
    "labels.\n",
    "\n",
    "We will model the rating distribution over the different features that\n",
    "we extract and create, and analyse how much each feature shifts our\n",
    "distribution. Using our results from this we will select good features\n",
    "to train on machine learning models.\n",
    "\n",
    "Using the labeled features that we construct, we will train different\n",
    "machine learning models like linear regression, nonlinear regression,\n",
    "logistic regression as well as neural networks, then make some\n",
    "predictions, and compare the accuracy obtained from them.\n",
    "\n",
    "## Team Members\n",
    "Jun Hee Kim, Nikhil Rangarajan, Sander Shi\n",
    "\n",
    "## Procedure\n",
    "* [Data Gathering from API](#step-1)\n",
    "* [Feature Extraction with Parsing](#step-2)\n",
    "* [Feature Analysis and Variable Selection](#step-3)\n",
    "* [Setup of Models](#step-4)\n",
    "* [Cross Validation](#step-5)\n",
    "* [Final Analysis](#step-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Imports and Definitions of Constants\n",
    "\n",
    "We will be using `pandas` to parse the data and `tensorflow` to construct the machine learning models. We will also be using the Yelp API to gather the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "API_URL = \"https://api.yelp.com/v3/businesses\"\n",
    "SEARCH_URL = API_URL + \"/search\"\n",
    "API_KEY = \"./API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step-1\"></a>\n",
    "\n",
    "## Part 1: Data Gathering from API\n",
    "\n",
    "In this step we will use the Yelp API to gather restaurant pages, then extract\n",
    "information using business search API requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "def find_restaurants(url, api_key_url):\n",
    "    \"\"\"\n",
    "    This function loads all restaurant data from restaurants in Pittsburgh.\n",
    "    \n",
    "    @input url: The API url.\n",
    "    @type url: String.\n",
    "    \n",
    "    @input api_key_url: The API key url.\n",
    "    @type api_key_url: String.\n",
    "    \n",
    "    @return: A Pandas DataFrame containing the restaurant URLs.\n",
    "    @rtype: pandas.DataFrame.\n",
    "    \"\"\"\n",
    "    # Retrieve API key\n",
    "    with open(api_key_url, 'r') as f:\n",
    "        api_key = f.readline().strip()\n",
    "        \n",
    "    # Set request header and params for search query\n",
    "    headers = {\n",
    "        'Authorization': ' '.join(['Bearer', api_key])\n",
    "    }\n",
    "    params = {\n",
    "        'term': 'restaurants',\n",
    "        'location': 'NYC'\n",
    "    }\n",
    "    response = requests.get(url=url, headers=headers, params=params)\n",
    "    return response\n",
    "\n",
    "all_restaurants = find_restaurants(SEARCH_URL, API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Feature Extraction with Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(raw_data):\n",
    "    \"\"\"\n",
    "    This function extracts the features from raw restaurant data.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "labeled_features = extract_features(all_restaurants_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 3: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_logistic(labeled_data):\n",
    "    \"\"\"\n",
    "    This function trains the features using logistic regression.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "theta = train_logistic(labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_net(labeled_data):\n",
    "    \"\"\"\n",
    "    This function trains the features using a neural network.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "thetas_nn = train_neural_net(labeled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Predictions and Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_logistic(features, trained):\n",
    "    \"\"\"\n",
    "    This functions gives a prediction using logistic regression.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def predict_nn(features, trained):\n",
    "    \"\"\"\n",
    "    This function gives a prediction using the neural net.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "prediction_logistic = predict_logistic(_, theta)\n",
    "prediction_nn = predict_nn(_, thetas_nn)\n",
    "\n",
    "def report_accuracy_logistic(trained):\n",
    "    pass\n",
    "\n",
    "def report_accuracy_nn(trained):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
